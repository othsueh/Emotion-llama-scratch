datasets:
  feature_face_caption:
    batch_size: 1
    sample_ratio: 30
    text_processor:
      train:
        name: blip_caption
    vis_processor:
      train:
        image_size: 224
        name: blip2_image_train
model:
  arch: minigpt_v2
  chat_template: true
  ckpt: /datas/store163/othsueh/Emotion-LLaMA/checkpoints/save_checkpoint/ckpt_fold_4/checkpoint_29.pth
  end_sym: </s>
  image_size: 224
  llama_model: /datas/store163/othsueh/Emotion-LLaMA/checkpoints/Llama-2-7b-chat-hf
  lora_alpha: 16
  lora_r: 64
  max_txt_len: 1024
  model_type: pretrain
  use_grad_checkpoint: true
run:
  amp: true
  device: cuda
  dist_url: env://
  distributed: true
  evaluate: false
  init_lr: 1e-5
  iters_per_epoch: 600
  job_name: minigptv2_finetune
  lr_sched: linear_warmup_cosine_lr
  max_epoch: 30
  min_lr: 1e-6
  num_workers: 6
  output_dir: /datas/store163/othsueh/Emotion-LLaMA/checkpoints/save_checkpoint/ckpt_fold_5/
  resume_ckpt_path: null
  seed: 42
  task: image_text_pretrain
  train_splits:
  - train
  wandb_log: false
  warmup_lr: 1e-6
  warmup_steps: 1000
  weight_decay: 0.05
  world_size: 2
